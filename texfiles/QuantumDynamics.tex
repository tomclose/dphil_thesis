\chapter{Quantum Dynamics} 
\label{ch:QuantumDynamics}

\section{Closed quantum systems}

We begin by quickly summarising the laws of quantum mechanics as applied to a \textit{closed system}; that is, a system which does not intereact in any way with other systems. In practice, it is rare that any given system can truly be considered to be closed, yet the dynamics of closed systems are fundamental to the quantum mechanical description of nature: at the highest level, we can view the universe itself an closed quantum system which contains all others.

By considering idealised closed systems, we are able to present the purest form of the rules of quantum mechanics - in the form of three postulate concerning the system's state, its evolution, and the act of performing measurements on it. In the latter parts of this chapter we will generalise the laws stated here to address \textit{open systems}, by first considering the open system as part of a larger closed system to which the postulates apply.

\subsection{State}

The first postulate concerns the description of the state of a system \cite{nielsen+chuang}:
\begin{quotation}
  Assosciated to any closed physical system is a Hilbert space known as the \textit{state space} of the system. The system is completely described by its \textit{state vector}, which is a unit vector in the system's state space. The state space of a composite physical system is the tensor product of the state spaces of the component physical systems.
\end{quotation}
A Hilbert space is (possibly infinite-dimensional) vector space over the complex numbers, on which an inner product is defined. We will usually write the state vector using the Dirac bracket notation, $\ket{\psi}$. Note that the postulate does not tell us anything more about the correct state space for a given system - we have to make that judgement when we model it.

In general, when a system can be described using a state vector we say that it exists in a \textit{pure state}. With the state vector specified we have complete knowledge about the system - we know everything that there is to know.

In QIP we are often concerned with physical systems where the state space is two-dimensional: the quantum bit or \textit{qubit}. The general state of such as system can be written
\begin{align}
  \ket{\psi} = \alpha\ket{0} + \beta\ket{1}
\end{align}
where the normalisation condition is imposed by requiring that $|\alpha|^2 + |\beta|^2 = 1$. As an alternative representation we can write
\begin{align}
  \ket{\psi} = \cos\frac{\theta}{2}\ket{0} + e^{i\phi}\sin\frac{\theta}{2}\ket{1}
\end{align}
where used the fact that two states are physically equivalent if they differ by a global phase, $\ket{a} = e^{ik}\ket{b}$, which will become apparent when we look at the measurement postulate. We can use this representation to visualise a qubit as a point on the surface of a unit sphere, known as the \textit{Bloch sphere}, described by the $3$-vector $[\cos(\phi)\sin(\theta), \sin(\phi)\sin(\theta), \cos(\theta)]$.

\subsection{Dynamics}

The second postulate concerns the evolution of an isolated quantum system and can be stated
\begin{quotation}
The time evolution of an isolated quantum system is described by the \textit{Schr\"odinger equation},
\begin{align}
  \label{qd:schrodinger_eq}
  i\hbar\ddt \ket{\psi(t)} = H(t) \ket{\psi(t)}
\end{align}
where $\hbar$ is a constant, known as \textit{Plank's constant}, and $H(t)$ is a fixed Hermitian operator known as the Hamiltonian of the closed system.
\end{quotation}
In the rest of this thesis we choose units so as to set $\hbar = 1$. 

The Schr\"odinger equation can be solved in terms of a time evolution operator
\begin{align}
  \ket{\psi(t)} = U(t)\ket{\psi(0)}
\end{align}
where $U(t)$ is the solution to the differential equation
\begin{align}
  \ddt U(t) = H(t)U(t), \qquad U(0) = \id
\end{align}
As $H(t)$ is Hermitian, $U(t)$ will be unitary. In particular this implies that $U^{-1}(t) = U^\dagger(t)$ exists and therefore the dynamics quantums of isolated quantum systems are reversible.

As the Hamiltonian is Hermitian we can write it in the form
\begin{align}
  H = \sum_i E_i \bra{\phi_i}\ket{\phi_i}
\end{align}
where $E_i$ are the eigenvalues, which are real, and $\ket{\phi_i}$ are the associated eigenvectors, which can be chosen to be orthogonal. The $\ket{\phi_i}$ are sometimes called stationary states, as they evolve as
\begin{align}
  \ket{\phi_i(t)} = e^{E_i t}\ket{\phi_i(0)}
\end{align}
picking up a phase at rate $E_i$.

As a simple example of pure state evolution we consider an isolated qubit, under the influence of the \textit{Rabi Hamiltonian},
\begin{equation} \label{rabi_hamiltonian}
  H = \frac{\hbar}{2}
\begin{bmatrix}
  -\nu & \Omega \\
  \Omega & \nu 
\end{bmatrix}.
\end{equation}

We diagonalise the Hamiltonian
\begin{align}
  H = E_1 \ket{\phi_1}\bra{\phi_1} + E_2 \ket{\phi_2}\bra{\phi_2}
\end{align}
in terms of the eigenvectors and eigenvalues
\begin{align}
  \ket{\phi_1} &=  \left(\cos\frac{\theta}{2}, \sin\frac{\theta}{2}\right)  &E_1 = \nu + \sqrt{\nu^2 - \Omega^2} \\
  \ket{\phi_2} &=  \left(\sin\frac{\theta}{2}, \cos\frac{\theta}{2}\right)  &E_2 = \nu - \sqrt{\nu^2 - \Omega^2} 
\end{align}
where
\begin{align}
  \theta = \arctan\left(\frac{\Omega}{\nu}\right).
\end{align}

We can then write the solution to the Schr\"odinger equation
\begin{align}
  \ket{\psi(t)} &= \alpha e^{iE_1t}\ket{\phi_1} +  \beta e^{iE_2t} \ket{\phi_2} \\
  &= \alpha e^{i\Delta t}\ket{\phi_1} +  \beta e^{- i\Delta t} \ket{\phi_2} 
\end{align}
where $\Delta = \sqrt{\nu^2 - \Omega^2}$ and the last equality uses the equivalence of two quantum states differing only by a global phase. 

The solution can be visualised a rotation of the initial state vector on the Bloch sphere at angular speed $\Delta$, about the axis connecting the diametrically opposite points relating $\ket{\phi_1}$ and $\ket{\phi_2}$. The amplitude of the oscillation is proportional to $\sin^2\theta$, increasing from $0$ to $1$ as $\theta \rightarrow \pi$.  This oscillatory behaviour, known in this case as the \textit{Rabi oscillation}, is a common feature of many quantum systems.

\subsection{Measurements}

The third, and final, postulate concerns itself with measurments performed on isolated quantum systems. We state it in terms of a special class of measurements
\begin{quotation}
  A \textit{prjective measurement} is described by an \textit{observable}, M, a Hermition operator on the system's state space. We can write the operator as
  \begin{align}
    M = \sum_m mP_m
  \end{align}
  where $P_m$ is the projector onto the eigenspace of $M$ with eigenvalue $m$. The outcomes of the measurement correspond to the eigenvalues $m$. When performing a measurement on state $\ket{\psi}$, the probability of obtaining outcome $m$ is
  \begin{align}
    p(m) = \bra{\psi}P_m\ket{\psi}.
  \end{align}
  Given that outcome $m$ occurred, the state of the system immediately after the measurement is
  \begin{align}
    \frac{P_m\ket{\psi}}{\sqrt{p(m)}}.
  \end{align}
\end{quotation}
In fact, projective measurements are not the most general measurement we can make on a closed quantum system. A projective measurement corresponds to making a measurement on the whole system. We could also choose to just measure a part of the system, which would not generally perform a projective measurement on the whole. We state postulate three in terms of projective measurements as they are conceptually simple and it can be shown that the most general types of measurements are always equivalent to a projective measurement on some ancilliary system \cite{neumark}. We visit these more general measurements along with open quantum systems in the next section.


\section{Open Quantum Systems}

In reality a closed quatum system must be viewed as in idealisation; with the possible exception of the entire universe, the assumption that a system is closed must always be approximate. All physical systems are unvoidably coupled to other physical systems. We could try to rectify the situation by expanding the system we are interested in to include these other systems, but will eventually run into difficulties: when considered together the joint system may be too complex to model given our computational resources, or perhaps we do not have enough knowledge of some of the systems or couplings to make modelling possible. To model real-world situations we must develop the theory of \textit{open quantum systems}. 

The subject of open quantum systems is especially important for the field of QIP. Most QIP processes and algorithms are stated in terms of what can be done in prinicple in ideal systems. All reals systems suffer from unwanted interactions with other systems. In assessing a system's suitability as a candidate QIP system, it is important to be able to somehow incorporate these interactions into our model and evaluate the extent of their effect on the system's information processing capacity.

In order to treat open systems we will need to generalise the ideas of state description, evolution and measurement that were introducted in the previous section.



\subsection{State}

When describing the state of closed systems we used the state vector. The state vector represents complete knowledge of the system. When we deal with open quantum systems, we frequently find ourselves in situations where we do not have this complete knowledge - there is some classical uncertainty in our knowledge of the state. In these cases the state vector is no longer sufficient for giving the best possible representation of the state. 

As a simple illustration of this point, consider a pair of qubits in the Bell singlet state, $\ket{01} - \ket{10}$. Imagine we only have access to the first qubit and want to provide the best possible description of its state; another party holds the second qubit and there are no restrictions placed on the operations they perform. A first observation is that if we perform a projective measurement described by the $Z$ operator we obtain the outcomes $0$ and $1$, each with probability $1/2$. The only state vectors with this property take the form $1/\sqrt{2}(\ket{0} + e^{i\phi}\ket{1})$, with $\phi \in [0, 2\pi)$. However, our first qubit also has the property that when measured in the $X$ or $Y$ basis it will also report both possible outcomes with equal probability, which is not the case for any of the state vectors given. A good representation of the state of the first qubit is not possible within the language of state vectors.

Systems where the state is not completely known and subsystems of composite systems can be thought of as being in a statistical mixture of pure states. We say these systems exist in a \textit{mixed state}. To describe such states, we introduce the \textit{density matrix}
\begin{align}
  \rho = \sum_i p_i \ket{\psi_i}\bra{\psi_i} 
\end{align}
which represents a statistical mixture of pure states $\ket{\psi_i}$ each with probability $p_i$. It can be seen immediately that a desity matrix must be Hermitian and positive semi-definite (has all eigenvalues $\geq 0$), and that $\tr(\rho) = 1$. It is also true that any matrix satisfying these properties will describe the state of some quantum ensemble.

When we introduced the concept of a mixed state we did not rule out that the state is also pure, merely that it need not be. We can consider a pure state to be a statistical mixture of a single state:
\begin{align}
  \rho = \ket{\psi}\bra{\psi}.
\end{align}
Pure states can be identified by the fact that $\tr\{\rho^2\} = 1$. In general $\tr\{\rho^2\}$ can be used as a measure of how mixed a state is. A maximally mixed state in a Hilbert space of dimesion $n$ has $\rho = 1/n\id$ and $\tr\{\rho^2\} = 1/n$.

If we have a composite quantum system formed from two systems $A$ and $B$ the density matrix of the joint system is given
\begin{align}
  \rho_{AB} = \rho_A \otimes \rho_B. 
\end{align}
If we are given the density matrix of the joint system, we can find the reduced desity matrix of the subsystem $A$ by taking the \textit{partial trace} over $B$
\begin{align}
  \rho_A = \tr_B\{\rho_{AB}\} = \sum_b \bra{b}\rho_{AB}\ket{b}
\end{align}
where $\{\ket{b}\}$ is a basis for the Hilbert space of system $B$. 

\subsection{Measurement}

A measurement on an isolated quantum system is described by a single operator. The possible measurement outcomes are given by the eigenvalues of the operator and the act of measurement projects the system into the eigenspace of the eigenvalue corresponding to the outcome. We refer to such measurements as \textit{projective measurements}.

When dealing with non-isolated systems we extend our measurement framework to \textit{positive operator valued measurements} (POVMs). Neumark's theorem \cite{?} tells us that any POVM on a system is equivalent to a projective measurement on a larger system. For example, a common experimental set-up is to allow a system to interact with an ancillia qubit and then projectively measure the ancillia to learn about the system.

A POVM  is defined by a set of operators $A_k$, satisfying
\begin{align}
  \label{POVM_completeness_eq}
  \sum_k A_k^\dagger A_k = \id
\end{align}
Each of the operators $A_k$ corresponds to a different measurement outcome $o_k$. The probability of outcome $o_k$ is given by $p_k = \tr\{A_k \rho A_k^\dagger\}$. After a measurement with outcome $o_k$ the system is left in the state
\begin{align}\label{POVM_normalisation_eq}
  \rho \rightarrow \rho' = \frac{1}{p_k} A_k \rho A_k^\dagger
\end{align}

\subsection{Dynamics}

In the language of density matrices the Schr\"odinger equation becomes the \textit{von Neumann equation}
\begin{align}
  \ddt \rho = i [\rho, H]
\end{align}

The von Neumann equation describes the evolution of a closed system in a mixed state, but the evolution of open systems is far richer than this. In general it may not even be possible to predict the evolution of an open system without also providing a detailed model of all the systems with which it interacts. The study of open quantum systems and the circumstances under which an interacting system's dynamics can be modelled alone is vast and here we will touch on only a small, yet often applicable, corner of it.

In order to set up the theory we first divide the world into two parts: the \textit{system} and the \textit{environment}. We choose the system to be the part that we wish to model and make predictions about. The environment represets everything outside the system. The decision of where to draw the boundary between system and environment in a given case requires much care.

We now look at the important case of \textit{Markovian evolution}: where the current evolution depends only on the system state at the current time, and not on the state of the environment or the history of the system. In practice this evolution will be approximate, but nevertheless provides accurate predictions in many situations. In particular, if the exitations in the environment decay on a much quicker timescale than that of the system dynamics, then the system's evolution is often approximately Markovian.

The most general form \cite{lindblad} of evolution of a Markovian system is given by the \textit{Markovian master equation}
\begin{align}\label{master_eq}
  \ddt \rho(t) = -i \left[H, \rho\right] + \sum_k L_k \rho L_k^\dagger -\frac{1}{2} L_k^\dagger L_k \rho -\frac{1}{2} \rho L_k^\dagger L_k .
\end{align}
The operators $L_k$ are often referred to as \textit{Lindblad operators} and term involving the sum is often referred to as the \textit{dissipator}, written $D(\rho)$. The $H$ that occurs in the commutator term is not necessarily the free system Hamiltonian, as it may contain corrective terms due to the interaction.

We now look at two situations in which the Markovian master equation arises.

\subsection{Quantum Jump Master Equation}

We first consider a system evolving under continuous measurement. It is important to state carefully what we mean by this to avoid an apparent contradiction: the well known quantum Zeno effect means that any system that is repeatedly projectively measured will not change its state at all. What we mean here is a system undergoing a weak, POVM-type measurement. A weak measurement is one that gives us very little information about the system and correspondingly only slightly perturbs the system's state. Such measurements occur when the system interacts weakly with an ancilla which is then measured.

We will focus on a specific type of continuous measurement, which can be phrased in terms of isolated detection events. Most of the time the measurement reveals that no event has occured, behaving like a weak measurement. Occasionally the measurement reveals that an event has occurred and the system changes drastically similar to a projective measurement. We say the system has undergone a \textit{quantum jump}. A good example is photon emission from an atom in a cavity: at any point it is possible that a photon will be emitted and detected, but in most time intervals no emission will occur.

It is important to realise that by placing a system under continuous observation we alter its dynamics even if no detection event occurs. Intuitively, the event of `no detectection' increases our knowledge of the system's state and thus changes it. We say the state follows \textit{no-jump evolution} due to the \textit{back-action} of our observation.

We will now roughly sketch out how this measurement scenario leads back to the Markovian master equation (\ref{master_eq}). The rigorous derivation requires the use of stochastic calculus and a good explanation can be found in \cite{brun}. We aim to avoid these complexities whilst still providing some level of intuition for the result. 

To put all this on a rigorous footing we will describe our observation using a POVM. For simplicity, we will assume that we look to detect only a single  event. We let the detection event operator be $A_1$, so that after a detection event the system is in state
\begin{align}
  \frac{A_1 \rho A_1^\dagger}{\tr\{A_1 \rho A_1^\dagger\}}
\end{align}
We let the measurement is \textit{weak} by setting $A_1 = \sqrt{\epsilon} L$ so that the probability of detecting an event is proportional to $\epsilon$, which we can take to be small. Currently $A_1$ represents one outcome of a POVM. To complete our description we must complete the set of measurement outcome operators so that eq (\ref{POVM_completeness_eq}) is satisfied. We do this by setting $A_0 = \id - \frac{\epsilon}{2} L^\dagger L$ so that
\begin{align}
  A_0^\dagger A_0 + A_1^\dagger A_1 = \left( \id - \frac{\epsilon}{2} L^\dagger L\right)^\dagger \left( \id - \frac{\epsilon}{2} L^\dagger L\right) + \epsilon L^\dagger L = \id + O(\epsilon^2)
\end{align}

We now consider the measurement to be made over a small time interval, $\delta t$, setting $\epsilon \propto \delta t$ so that the probability of detection is proportional to the length of that interval. We absorb any constant factor into our definition of $L$. We also make the simplifying assumption that the system is stationary apart from the measurement process, so the Hamiltonian is $0$. Conditional on there being no jump in the interval the system evolves as
\begin{align}
  \rho(t+\delta t) &= \frac{1}{p_0(t, t+\delta t)}\left(\id - \frac{\delta t}{2} L^\dagger L\right)\rho(t)\left(\id - \frac{\delta t}{2} L^\dagger L\right) \\
  &= \frac{1}{p_0(t, t+\delta t)}\left(\rho(t) - \frac{\delta t}{2} \left(L^\dagger L \rho(t) + \rho(t) L^\dagger L \right)\right)
\end{align}
where we have normalised the state $\rho$ by dividing by the probability that no jump occured in the interval, $p_0(t, t+\delta t)$. This normalisation is not ideal as, due to the dependence of $p_0(t, t+\delta t)$ on $\rho(t)$, it introduces a non-linearity into the equation. We can avoid this by simply not performing the normalisation, which has the nice feature that the probability $p_0(t, t+\delta t)$ is now encoded in the trace of the density matrix. As the outcomes of measurements in different time intervals are independent, the probabilities multiply, and the so the trace of the density matrix $\rho(t)$ will represent the cumulative probability there has been no jump by time $t$.

We can use this equation to deduce the continuous conditional no-jump dynamics of the system by allowing $\delta t \rightarrow dt$: [TODO do I need to talk about Zeno here - see Brun page 8? Is Brun wrong?]
\begin{align}
  \ddt \rho_c(t) = - \frac{1}{2} \left(L^\dagger L \rho_c(t) + \rho(t) L^\dagger L \right)
\end{align}
This makes precise the earlier statement that the act of not detecting an event has a tangible effect on the physical system.

In a similar fashion to before we can look at what happens if we do detect an event in the interval $\delta t$. Conditional on an event being detected the system evolves as
\begin{align}
  \rho(t + \delta t) = L\rho(t)L^\dagger
\end{align}
where we have chosen not to normalise, so that the trace of $\rho(t + \delta t)$ records the probability that an event was detected.

If we average over these two possible outcomes we obtain the equation
\begin{align}
\frac{\rho(t + \delta t) - \rho(t)}{\delta t} = L\rho(t)L^\dagger- \frac{1}{2} \left(L^\dagger L \rho(t) + \rho(t) L^\dagger L \right).
\end{align}
By allowing $\delta t \rightarrow dt$ we recover the Markovian master equation (\ref{master_eq}). 

Such an averaging procedure would be justified if, for example, we performed the measurement but forgot to look at the outcome. Perhaps a better way of viewing it is that Nature measured the system. The result is in priciple recorded in the environment but we do not have access to it. In this way we can interpret decoherence processes as described by the Markovian master equation in terms of information leaking from the system into the environment.

It also allows us to view the Markovian master equation as an averaging over all possible trajectories of the system. It is sometimes useful to think in terms of \textit{unravelling} a master equation into the different trajectories. A simple example would be to pull out the no-jump component that we derived above, to unravel the evolution into no-jump and at-least-one-jump processes.


\subsection{Decoherence Master Equation}

We have so far presented the general form of a Markovian Master Equation and seen how such an equation can be interpreted as the average over the different observation histories of a continuously observed quantum system. We now approach the master equation from a different direction by deriving it directly from the system-environment Hamiltonian. In doing so we visit some of the common assumptions made to cast the system into Markovian form, as well as deriving an equation that will be of use in the single photon source work in Chapter \ref{ch:SinglePhotonSource}.

Start with following the general derivation of a weakly interacting system-environment.

Need that $H_S$, $H_E$ and $H_I$? are constant

We begin by separating the Hamiltonian into terms acting solely on the system, terms acting solely on the environment, and terms involving both the system and environment (the interaction terms):
\begin{align}
  H(t) = H_S + H_E + H_I.
\end{align}

In order to simplify our description of the system evolution, we change to the \textit{interaction picture}: we let $U(t) = \exp(i(H_S + H_E)t)$ and transform operators as $\tilde{A}(t) = U(t)A(t)U^\dagger(t)$. The von Neumann equation is transformed to
\begin{align}
  \label{i_von_neumann_eq}
  \ddt \tilde{\rho}(t) = -i\left[ \tilde{H}_I(t), \tilde{\rho}(t) \right]
\end{align}
By switching to the interaction picture we move to a basis which follows the natural, independent evolution of both the system and environment. The natural motion of the system and environment have thus been absorbed into our description of the states, and so the terms $H_S$ and $H_E$ are eliminated from the Hamiltonian.

Our best description of the state of the system $S$ is given by taking the partial trace of the overall density matrix over the envonment $E$:
\begin{align}
  \label{trace_eq}
  \tilde{\rho}_S(t) = \tr_E\left\{\tilde{\rho}(t)\right\}.
\end{align}

We now look to find the master equation for the system S, which will be an expression for the rate of change of $\tilde{\rho}_S$ in terms of $\tilde{\rho}_S$. To this end, we formally solve eq. (\ref{i_von_neumann_eq}) to find an equation for $\tilde{\rho}$ in integral form
\begin{align}
  \tilde{\rho}(t) = \tilde{\rho}(0) + -i\int_{s=0}^t \left[ \tilde{H}_I(s), \tilde{\rho}(s) \right] dt
\end{align}
and then substitute this back into eq. (\ref{i_von_neumann_eq}) and apply eq. (\ref{trace_eq}) to get
\begin{align}
  \label{before_markov_approx}
  \ddt \tilde{\rho}_S(t) = -\int_{s=0}^t \tr_B\left\{ \left[ \tilde{H}_I(t), \left[ \tilde{H}_I(s), \tilde{\rho}(s) \right] \right] \right\} dt
\end{align}
where we have assumed that $\tr_B [H_I(t), \rho(0)] = 0$.


This isn't yet in a closed form as the right hand side still contains $\rho(t)$, the density matrix of the whole system.

We then make the Born approximation letting $\tilde{\rho}(s) \approx \tilde{\rho}_S(s) \otimes \tilde{\rho}_E$. At first glance this appears to say that the environment is completely unaffected by the system. In fact we still allow exitations from the system to enter the environment; the assumption is merely that these exitations dissipate on a short timescale to become undetectable.

After the Born approximation the RHS of eq. (\ref{before_markov_approx}) no longer depends on the history of the environment, but still depends on the system state at previous times. To remove this dependence we make the \textit{Markov approximation} by setting $\rho(s) = \rho(t)$
\begin{align}
  \ddt \tilde{\rho}_S = -i \int_{s=0}^t \tr_E\left\{\left[ \tilde{H}_I(t), \left[ \tilde{H}_I(s), \tilde{\rho}_S(t)\otimes\tilde{\rho}_E \right] \right]\right\} ds
\end{align}
This equation is known as the Redfield equation. 

The Redfield equation only depends on current state of the system, but still contains a reference to the initial time $t=0$. To remove this we make the second part of the Markov approximation, by integrating backwards in time. 
\begin{align}
  \label{redfield_eq}
  \ddt \tilde{\rho}_S(t) = -i \int_{s=0}^\infty \tr_B\left\{\left[ \tilde{H}_I(t), \left[ \tilde{H}_I(t-s), \tilde{\rho}(t) \right] \right]\right\} ds
\end{align}
This assumes that the integrand dissapears sufficiently quickly. We would expect this to happen on the timescale of dissipation of environmental excitations, so the \textit{Born-Markov approximation} is suitable for modelling the system on a timescale larger than this.

We now look get the equation into a form where we can perform the integral by examining the form of the Hamiltonian. We begin by returning to the Schr\"odinger picture Hamiltonian and writing
\begin{align}
  H_I = \sum_\alpha A_\alpha \otimes B_\alpha
\end{align}
where $A_\alpha$ and $B_\alpha$ act on the system and environment respectively.

To find the time dependence of $\tilde{H}_I(t)$ we further split the $A_\alpha$ into operators 
\begin{align}
  A_\alpha(\omega) = \sum_{\epsilon' - \epsilon = \omega} \Pi(\epsilon)A_\alpha \Pi(\epsilon')
\end{align}
where $\Pi(\epsilon)$ is a projector onto the eigenspace of energy $\epsilon$. This gives us that
\begin{align}
  [H_S, A_\alpha(\omega)] &= - \omega A_\alpha(\omega) \\
  [H_S, A^\dagger_\alpha(\omega)] &= + \omega A^\dagger_\alpha(\omega)
\end{align}
The $A_\alpha(\omega)$ are eigenoperators of the Hamiltonian with frequencies $\pm \omega$.

Returning to the interaction picture we have
\begin{align}
  \tilde{A}(\omega, t) = e^{iH_S t}A_\alpha(\omega) e^{-iH_S t} = e^{-i\omega t} A_\alpha(\omega)
\end{align}
so that
\begin{align}
  \tilde{H}_I(t) = \sum_{\alpha, \omega} e^{-i \omega t} A_\alpha(\omega)\otimes \tilde{B}_\alpha(t) = \sum_{\alpha, \omega} e^{i \omega t} A^\dagger_\alpha(\omega)\otimes \tilde{B}^\dagger_\alpha(t)
\end{align}

If we substitute this back into the Redfield eq. (\ref{redfield_eq}) we are able to perform the integration
\begin{align}
  \ddt \tilde{\rho}_S(t) = \sum_{\omega, \omega'} \sum_{\alpha, \beta} e^{i(\omega'-\omega)t} \Gamma_{\alpha\beta}(\omega)\left(A_\beta(\omega)\tilde{\rho}_S(t)A^\dagger_\alpha(\omega') - A^\dagger_\alpha(\omega')A_\beta(\omega)\right) + \text{H.c}
\end{align}
where
\begin{align}
  \Gamma_{\alpha\beta}(\omega) = \int_0^\infty ds e^{i\omega s} \tr_E \{ \tilde{B}_\alpha^\dagger(t) \tilde{B}_\beta(t-s) \rho_E \}
\end{align}
We have assumed that $\rho_E$ is a stationary state of the environment, so that $\tr_E \{\tilde{B}_\alpha^\dagger(t) \tilde{B}_\beta(t-s) \rho_E \} = \tr_E \{\tilde{B}_\alpha^\dagger(s) \tilde{B}_\beta(0) \rho_E \}$ and $\Gamma_{\alpha\beta}(\omega)$ has no time dependence.


We now ignore the terms where $\omega' - \omega \neq 0$. This is equivalent to the RWA
\begin{align}
  \ddt \tilde{\rho}_S(t) = \sum_{\omega} \sum_{\alpha, \beta} \Gamma_{\alpha\beta}(\omega)\left(A_\beta(\omega)\tilde{\rho}_S(t)A^\dagger_\alpha(\omega) - A^\dagger_\alpha(\omega)A_\beta(\omega)\right) + \text{H.c}
\end{align}

If we write
\begin{align}
  \Gamma_{\alpha \beta}(\omega) = \frac{1}{2}\gamma_{\alpha\beta}(\omega) + i S_{\alpha\beta}(\omega)
\end{align}
and return to the Schr\"odinger picture, then we recover
\begin{align}
  \ddt \rho_S(t) = -i[H_S + H_{LS}, \rho_S(t) ] + \sum_\omega \sum_{\alpha, \beta} \gamma_{\alpha\beta}(\omega)\left(A_\beta(\omega)\rho_S(t)H_\alpha^\dagger(\omega) - \frac{1}{2}\{A^\dagger_\alpha(\omega)A_\beta(\omega), \rho_S(t)\} \right)
\end{align}
where we have the Lamb shift Hamiltonian contribution $H_{LS}$. We can now diagonalise the matrix $\gamma_{\alpha\beta}$ to recover the Master Equation form in eq (\ref{master_eq}).

\section{Quantum Treatment of Light}

Wave particle duality.

There are two approaches to modelling light: classical and quantum. 

When quantizing the electromagnetic field it is convenient to work in terms of creation and annihilation operators, $\cre{a}_\lambda(\vec{k})$ and $\an{a}_\lambda(\vec{k})$, for field modes
\begin{align}
  u(\vec{k}; \vec{r}, t) \propto e^{i\vec{k} \cdot \vec{r} - i\omega_\vec{k} t}
\end{align}
with polarization $\lambda$. The mode $u(\vec{k}; \vec{r}, t)$ describes a plane wave with definite momentum $\vec{k}$, which is unphysical due to its infinite extend in space. Nevertheless these modes are very useful when describing light quantum mechanically.

In terms of these operations, the Hamiltonian for the free field is given by
\begin{align}
  H &= \sum_\lambda \int d\vec{k} \frac{\hbar\omega_k}{2} \left[ \cre{a}_\lambda(\vec{k})\an{a}_\lambda(\vec{k}) + \an{a}_\lambda(\vec{k})\cre{a}_\lambda(\vec{k}) \right] \\
  &= \sum_\lambda \int d\vec{k} H_\lambda(\vec{k}).
\end{align}

The creation and annihilation operators are so-called as they can be thought to as adding or removing an excitation in a given mode. Commutation relation $[\an{a}_\lambda(\vec{k}), \cre{a}_{\lambda '}(\vec{k}')]  = \delta_{\lambda\lambda '}\delta^3(\vec{k} - \vec{k}') $.

We have that
\begin{align}
  \left[H, \an{a}_\lambda(\vec{k})\right] = -\hbar \omega_\vec{k} \an{a}_\lambda(\vec{k})
  \quad \text{and} \quad 
  \left[H, \cre{a}_\lambda(\vec{k})\right] = \hbar \omega_\vec{k} \cre{a}_\lambda(\vec{k})
\end{align}

Suppose we have a state $\ket{\psi}$ which is an eigenstate of the Hamiltonian with energy $E$. Consider the state $\cre{a}\ket{\psi}$:
\begin{align}
  H\cre{a}_\lambda(\vec{k})\ket{\psi} &= \left(\hbar \omega_\vec{k} \cre{a}_\lambda(\vec{k}) + \cre{a}_\lambda(\vec{k})H\right) \ket{\psi} \\
  &= \left(\hbar \omega_\vec{k} + E\right) \cre{a}_\lambda(\vec{k})\ket{\psi}
\end{align}
so $\cre{a}_\lambda(\vec{k})\ket{\psi}$ is also an eigenstate of the Hamiltonian, this time with energy $E + \hbar\omega_\vec{k}$. The operator $\cre{a}_\lambda(\vec{k})$ has created an excitation with energy $\hbar \omega_\vec{k}$.

If we start with a vacuum state of the electomagnetic field $\ket{0}$ such that $H\ket{0} = 0$ [TODO?? is this right] we can use the operators $\cre{a}$ to define set of states:
\begin{align}
  \ket{n} = (\cre{a})^n \ket{0}
\end{align}
These are called the \textit{Fock states} and corespond to states with a definite number of excitations.These are called the \textit{Fock states} and corespond to states with a definite number of excitations.  


Single photon states

\subsection{Hong-Ou-Mandel Dip}

The Hong-Ou-Mandel experiment concerns the behaviour of a pair of photons iteracting with a \textit{beam splitter}. A beam splitter is an optical device that reflects some of the incident light while allowing the rest to pass through. Given two optical modes $a_1$ and $a_2$ the beam splitter performs the transformation
\begin{align}
  \an{a}_{1} \rightarrow \an{a}_{1} + \an{a}_{2} \\
  \an{a}_{2} \rightarrow \an{a}_{1} - \an{a}_{2}
\end{align}
If both modes are incident on the beam splitter simultateously,
\begin{align}
  \an{a}_{1}\an{a}_{2} \rightarrow \left(\an{a}_{1} + \an{a}_{2}\right) \left(\an{a}_{1} - \an{a}_{2}\right) = \an{a}_{1}\an{a}_{1} - \an{a}_{2}\an{a}_{2}
\end{align}
The output states contain only those cases where both exitations are in the same mode.

So if we have two single mode exitations of a given frequency incident on different arms of a beam splitter they exihit a `bunching' behaviour: they will leave on the same arm. As already discussed, single mode exitations are not physical. Does a similar result apply to a pair of single photons arriving at a beam splitter?

A single photon can be written in terms of its annihilation operator
\begin{align}
  \an{b} = \int f(k) \an{a} dk
\end{align}

\begin{align}
  \an{b}_1 \an{b}_2 & = \int \int f_1(k)f_2(k') \an{a}_1(k) \an{a}_2(k') dkdk' \\
                    & \rightarrow
\end{align}

\subsection{Input-Output formalism}



\section{Light-Matter interactions}

\subsection{Atom in a cavity}

Atom couples to the electric field through the dipole coupling $H_d = -\vec{d}\cdot\vec{E}(t)$ where $\vec{d} = -e \vec{r}$ for the charge $e$ and the position operator $\vec{r}$.

We look at the case of an atom in a cavity. In a cavity only a discrete set of modes can exist, which simplifies the calculation.

We also assume that the lowset mode frequency is nearly resonant with the atomic transition, which will allow us to ignore higher modes later in the calculation.

Look at a two level system with Hamiltonian
\begin{align}
  H = -\frac{\omega_0}{2}\ket{g}\bra{g} +\frac{\omega_0}{2}\ket{e}\bra{e}
\end{align}
We call $\ket{g}$ the ground state and $\ket{e}$ the excited state. 


Classically the electric field $\vec{E}$ is given
\begin{align}
  \vec{E} = E_0 (\vec{\epsilon}\exp(i[\omega t - \vec{k}\cdot\vec{n}r]) + \vec{\epsilon}^*\exp(-i[\omega t - \vec{k}\cdot\vec{n}r])
\end{align}

We assume that we may treat the atom's center of mass classically and that the atom is positioned at $r=0$.

We need to write the dipole Hamiltonian, $H_d$, in terms of our system basis $\{\ket{g}, \ket{e}\}$
As the position operator $\vec{r}$ has odd parity, [??], the diagonal elements $\bra{g}H_d\ket{g}$ and $\bra{e}H_d\ket{e}$ must both be equal to $0$. As the Hamiltonian is Hermitian there is only one element left to specify:
\begin{align}
  \bra{e}H_d\ket{g} = \bra{g}H_d\ket{e}^* = E_0e\vec{r}_{eg}\cdot(\vec{\epsilon}\exp(i\omega t) + \vec{\epsilon}^*\exp(-i\omega t))
\end{align}
where $\vec{r}_{eg} = \bra{e}\vec{r}\ket{g}$

Over all this leaves us with the Hamiltonian
\begin{align}
  H =
  \begin{bmatrix}
    -\omega_0/2 & eE_0\vec{r}_{eg}^*\cdot(\vec{\epsilon}^*\exp(-i\omega t) + \vec{\epsilon}\exp(i\omega t)) \\
    eE_0\vec{r}_{eg}\cdot(\vec{\epsilon}\exp(i\omega t) + \vec{\epsilon}^*\exp(-i\omega t)) & +\omega_0/2
  \end{bmatrix}
\end{align}

Still time dependent. Make a unitary transformation to rotate with the EM field:
\begin{align}
  U(t) =
  \begin{bmatrix}
    e^{i\omega t/2} & 0 \\
    0 & e^{-i\omega t/2}
  \end{bmatrix}
\end{align}

This gives us
\begin{align}
  H =
  \begin{bmatrix}
    -\omega_0/2 & eE_0\vec{r}_{eg}^*\cdot(\vec{\epsilon}^* + \vec{\epsilon}\exp(2i\omega t)) \\
    eE_0\vec{r}_{eg}\cdot(\vec{\epsilon} + \vec{\epsilon}^*\exp(-2i\omega t)) & +\omega_0/2
  \end{bmatrix}
\end{align}

We now make the rotating wave approximation, neglecting the fast rotating terms $e^{2i\omega t}$ and $e^{-2i\omega t}$ on the basis that they will be far off-resonance and their contribution will average to zero over time. 

We are left with
\begin{align}
  H =
  \begin{bmatrix}
    -\omega_0/2 & eE_0\vec{r}_{eg}^*\cdot\vec{\epsilon}^* \\
    eE_0\vec{r}_{eg}\cdot\vec{\epsilon} & +\omega_0/2
  \end{bmatrix}
\end{align}
which is of the form of the Rabi Hamiltonian (\ref{rabi_hamiltonian}). An atom in a cavity interacting with an EM field will oscillate.

If we want to look at the emission and absorbtion of single photons we must instead use the fully quantised field. The electric field is then given 
\begin{align}
  \vec{E} = \sum_{\lambda = 1}^2 \sum_\vec{k} E_0 (\vec{\epsilon}_\lambda(\vec{k})\an{a}_\lambda(\vec{k})+ \vec{\epsilon}^*_\lambda(\vec{k})\cre{a}_\lambda(\vec{k})
\end{align}



\begin{align}
  H = \frac{\hbar \omega_0}{2} \sz + \hbar \omega \cre{b}\an{b} + g\an{b} \sp + g^{*}\cre{b} \sm
\end{align}

\subsection{Raman procedure}


\begin{align}
  H=\hbar
  \begin{bmatrix}
    0 & 0 & \Omega_1 \cos\omega_1 t \\
    0 & \delta & \Omega_2 \cos\omega_2 t \\
    \Omega_1 \cos\omega_1 t & \Omega_2 \cos\omega_2 t & \omega
  \end{bmatrix}
\end{align}

\begin{align}
  U(t) = 
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & e^{i(\omega_1 - \omega_2)t} & 0 \\
    0 & 0 & e^{\omega_1 t}
  \end{bmatrix}
\end{align}

\begin{align}
  \tilde{H}=\frac{\hbar}{2}
  \begin{bmatrix}
    0 & 0 & \Omega_1(1+e^{2i\omega_1 t}) \\
    0 & 2(\delta + \omega_2 - \omega_1) & \Omega_2 (1+e^{2i\omega_2 t}) \\
    \Omega_1(1+e^{2i\omega_1 t}) & \Omega_2 (1+e^{2i\omega_2 t}) & 2(\omega - \omega_1)
  \end{bmatrix}
\end{align}

After we make the rotating wave approximation
\begin{align}
  \tilde{H}=\frac{\hbar}{2}
  \begin{bmatrix}
    0 & 0 & \Omega_1 \\
    0 & 2(\nu_1 - \nu_2) & \Omega_2  \\
    \Omega_1 & \Omega_2  & 2\nu_1
  \end{bmatrix}
\end{align}

Look at the limit $\nu \gg \{\Omega_1, \Omega_2\}$.  Degenerate perturbation theory
\begin{align}
  H = -\frac{1}{4\nu}
  \begin{bmatrix}
    \Omega_1^2 & \Omega_1 \Omega_2 \\
    \Omega_1\Omega_2 & \Omega_2^2
  \end{bmatrix}
\end{align}
which is the basically the Rabi Hamiltonian as in Eq. (\ref{rabi_hamiltonian}).

Oscillation with angular frequency $\Delta = (\Omega_1^2 + \Omega_2^2)/4\nu$ induced via the third state.



\section{Phonon-matter interactions}

When dealing with solid state systems an important source of decoherence comes from interaction with lattice vibrations. Following a similar pattern to the quantisation of the electromagnetic field, we can quantise the vibrational modes of a lattice, in terms of \textit{phonons}, quanta of vibrational energy.

Phonons couple to any states of our system that lead to a distortion in the atomic lattice. We restrict ourselves to looking at relatively low-energy states, coupling only to long-wavelength, accoustic phonons. There are two dominant coupling mechanisms in this case: \textit{deformation potential} coupling, $D$, and \textit{piezoelectric coupling}, $P$, \cite{mahan} leading to the interaction Hamiltonian
\begin{align}
  H = \sum_\vec{q} \sqrt{\frac{\hbar}{2\mu V\omega_\vec{q}}} \left(D \vert \vec{q}\vert + iP \right)\hat{g}(\vec{q})\left(\an{a}_\vec{q} + \cre{a}_{-\vec{q}} \right).
\end{align}
[Find mahan and add something interesting]

We also restrict ourselves to looking at coupling to a phonon bath in a thermal state
\begin{align}
  \rho_E = \frac{1}{Z_\beta} e^{-\beta H_E}
\end{align}
where $\beta = 1/(kT)$ and
\begin{align}
  H_E = \sum_\alpha \omega_\alpha \cre{b}_\alpha \an{b}_\alpha
\end{align}

In this state we can calculate the correlation functions explicitly
\begin{align}
  \langle \an{b}_i \an{b}_j \rangle &= 0 \\
  \langle \cre{b}_i \cre{b}_j \rangle &= 0 \\
  \langle \an{b}_i \cre{b}_j \rangle &= \delta_{ij} \left( N(\omega_i) +1 \right) \\
  \langle \cre{b}_i \an{b}_j \rangle &= \delta_{ij} N(\omega_i)
\end{align}
where
\begin{align}
  N(\omega) \frac{1}{e^{\beta \omega} - 1}
\end{align}
is the occupation of state $i$.

When we take the sum over $\vec{q}$ we end up with 
\begin{align}
  J(\omega) = 2\pi \sum_\vec{q} |g_\vec{q}|^2 \delta(\omega-\omega_\vec{q})
\end{align}
so that we get
\begin{align}
  \gamma_\alpha(\omega) = \left\{
    \begin{array}{l l}
    J(\omega)\left(N(\omega) + 1\right) & \qquad \text{if $\omega > 0$}\\
    J(\omega)N(\omega) & \qquad \text{if $\omega \leq 0$}
  \end{array} \right.
\end{align}

